# rpi\_phoWhisper

A lightweight pipeline on Raspberry PiÂ 5 for recording audio, transcribing with a custom PhoWhisper model, and (optionally) processing transcriptions via a PhoBERT NLU model.

---

## ğŸ“– Overview

This repository provides scripts to:

1. **Record audio** in continuous 10â€‘second WAV chunks via a USB microphone.
2. **Transcribe** each chunk to text using a custom-finetuned PhoWhisper model.
3. **(Optional)** Perform NLU (e.g., intent classification) using a custom-finetuned PhoBERT model.
4. **Run as daemons** for continuous operation, or test manually step-by-step.

Designed for ease of use: clone, configure a Python virtual environment, install dependencies, and run.

---

## ğŸš€ Prerequisites

* **Hardware**: Raspberry PiÂ 5 (16â€¯GB RAM) with USB microphone.
* **OS**: Raspberry Pi OS (64â€‘bit).
* **Python**: 3.11 (installed via system).
* **Git**: for cloning the repo.

---

## ğŸ“‚ Repository Structure

```plaintext
rpi_phoWhisper/
â”œâ”€ .gitignore
â”œâ”€ README.md
â”œâ”€ run.sh
â”œâ”€ system/
â”‚  â””â”€ install.sh
â”œâ”€ python/
â”‚  â”œâ”€ daemon_audio.py
â”‚  â”œâ”€ daemon_stt.py
â”‚  â””â”€ daemon_nlu.py
â”œâ”€ models/
â”‚  â”œâ”€ phowhisper/    â† custom PhoWhisper model files
â”‚  â””â”€ phobert/       â† (optional) custom PhoBERT model files
â”œâ”€ data/             â† automatically created
â”‚  â”œâ”€ audio_chunks/
â”‚  â”œâ”€ transcriptions/
â”‚  â””â”€ nlu_results/
â””â”€ venv/             â† Python virtual environment
```

---

## âš™ï¸ Setup

1. **Clone the repository**:

   ```bash
   git clone https://github.com/quanghuytv12/rpi_phoWhisper.git
   cd rpi_phoWhisper
   ```

2. **Create & activate a virtual environment**:

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**:

   ```bash
   bash system/install.sh
   ```

   This will:

   * install system packages (`portaudio19-dev`, etc.)
   * install Python libraries (`torch`, `torchaudio`, `transformers`, `pyaudio`)
   * create `data/` subfolders

4. **Verify data directories**:

   ```bash
   ls data
   # â†’ audio_chunks  transcriptions  nlu_results
   ```

5. **Add custom models**:

   * Copy your PhoWhisper model to `models/phowhisper/`.
   * (Optional) Copy your PhoBERT model to `models/phobert/`.

6. **Configure microphone device** (if needed):

   * List audio devices:

     ```bash
     arecord -l
     ```
   * Edit `python/daemon_audio.py`, set `DEVICE_INDEX` to your USB mic index:

     ```python
     DEVICE_INDEX = 1
     ```

---

## â–¶ï¸ Usage

### 1. Audio â†’ STT only

Run just recording and transcription:

```bash
# ensure venv is active
source venv/bin/activate
# start audio & STT daemons
bash run.sh  # remove or comment out daemon_nlu.py line
```

### 2. Manual step-by-step

* **Record one chunk**:

  ```bash
  python3 python/daemon_audio.py
  # press Ctrl+C after one file saves
  ```
* **Transcribe that chunk**:

  ```bash
  python3 python/daemon_stt.py
  ```
* **View transcription**:

  ```bash
  cat data/transcriptions/*.txt
  ```

### 3. Full pipeline (including NLU)

After adding PhoBERT model:

```bash
source venv/bin/activate
python3 python/daemon_audio.py &
python3 python/daemon_stt.py &
python3 python/daemon_nlu.py &
echo "All daemons running"
```

## ğŸ¤ Contributing

Feel free to open issues or pull requests for improvements (logging, Docker, systemd services, etc.).

---

## ğŸ“„ License

MITÂ License. See [LICENSE](LICENSE) if provided.
